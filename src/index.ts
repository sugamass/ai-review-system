import "dotenv/config";
import { graphDataTestRunner } from "@receptron/test_utils";
import * as agents from "@graphai/agents";
import { GraphData } from "graphai";
import {
  LLMOption,
  selectLLMAgentInfo as selectLLMAgent,
} from "./select_llm_agent";
import { averageScoreAgentInfo as averageScoreAgent } from "./average_score_agent";
import deepseekAgent from "./deepseek_agent";

const llmOptions: LLMOption[] = [
  {
    name: "chatgpt",
    agentName: "openAIAgent",
    model: "gpt-4o",
    apiKey: process.env.OPENAI_API_KEY,
  },
  {
    name: "deepseek",
    agentName: "deepseekAgent",
    model: "deepseek-chat",
    apiKey: process.env.DEEPSEEK_API_KEY,
  },
  {
    name: "gemini",
    agentName: "geminiAgent",
    model: "gemini-2.0-flash",
    apiKey: process.env.GEMINI_API_KEY,
  },
];

const graph_data: GraphData = {
  version: 0.6,
  loop: {
    while: ":continue",
  },
  nodes: {
    continue: {
      // Holds a boolean data if we need to continue this chat or not.
      value: true,
      update: ":checkInput",
    },
    proofreadMessages: {
      value: [
        {
          role: "system",
          content:
            "次に与える文章の正確さを、0から100の数値で評価してください。100が完全に正しい、0が全く正しくないとします。数値だけ出力してください。理由や説明は必要ありません。",
        },
      ],
    },
    userLLMTypeInput: {
      // Receives an input from the user.
      agent: "textInputAgent",
      params: {
        message: "chatgpt or gemini or deepseek:",
      },
    },
    checkLLMTypeInput: {
      // Checks if the user enters a valid llm type.
      agent: (namedInputs) => {
        const { userLLMTypeInput, llmOptions } = namedInputs;
        const exists = llmOptions.some(
          (llmOption: LLMOption) => llmOption.name === userLLMTypeInput
        );
        return exists;
      },
      inputs: {
        userLLMTypeInput: ":userLLMTypeInput.text",
        llmOptions: llmOptions,
      },
    },
    checkInput: {
      agent: "compareAgent",
      inputs: {
        array: [":userLLMTypeInput.text", "!=", "/bye"],
      },
    },
    notLLMType: {
      agent: "stringTemplateAgent",
      unless: ":checkLLMTypeInput",
      inputs: { text: "Please enter a valid LLM type." },
      console: {
        after: true,
      },
    },
    selectLLMAgent: {
      agent: "selectLLMAgent",
      params: {
        llmOptions: llmOptions,
      },
      inputs: {
        selectedLLMName: ":userLLMTypeInput.text",
      },
      if: ":checkLLMTypeInput",
    },
    promptInput: {
      agent: "textInputAgent",
      params: {
        message: "Please enter text:",
      },
      if: ":checkLLMTypeInput",
    },
    generateTextLLM: {
      agent: ":selectLLMAgent.selectedLLM.agentName",
      params: {
        model: ":selectLLMAgent.selectedLLM.model",
        apiKey: ":selectLLMAgent.selectedLLM.apiKey",
      },
      inputs: { prompt: ":promptInput.text" },
    },
    proofreadAgentA: {
      agent: ":selectLLMAgent.proofreadLLM_A.agentName",
      params: {
        model: ":selectLLMAgent.proofreadLLM_A.model",
        apiKey: ":selectLLMAgent.proofreadLLM_A.apiKey",
      },
      inputs: {
        messages: ":proofreadMessages",
        prompt: ":generateTextLLM.text",
      },
    },
    proofreadAgentB: {
      agent: ":selectLLMAgent.proofreadLLM_B.agentName",
      params: {
        model: ":selectLLMAgent.proofreadLLM_B.model",
        apiKey: ":selectLLMAgent.proofreadLLM_B.apiKey",
      },
      inputs: {
        messages: ":proofreadMessages",
        prompt: ":generateTextLLM.text",
      },
    },
    avereageScoreAgent: {
      agent: "averageScoreAgent",
      inputs: {
        scores: [":proofreadAgentA.text", ":proofreadAgentB.text"],
      },
    },
    textOutput: {
      agent: "stringTemplateAgent",
      inputs: {
        text: "Text generated by ${:selectLLMAgent.selectedLLM.name}\n${:generateTextLLM.text}",
      },
      console: {
        after: true,
      },
    },
    scoreOutput: {
      agent: "stringTemplateAgent",
      inputs: {
        text: "Output by ${:selectLLMAgent.proofreadLLM_A.name}:${:proofreadAgentA.text}\nOutput by ${:selectLLMAgent.proofreadLLM_B.name}: ${:proofreadAgentB.text}\nAverage accuracy score:${:avereageScoreAgent.score}",
      },
      console: {
        after: true,
      },
      isResult: true,
    },
  },
};

export const main = async () => {
  const result = await graphDataTestRunner(
    __dirname + "/../",
    __filename,
    graph_data,
    {
      ...agents,
      selectLLMAgent: selectLLMAgent,
      averageScoreAgent,
      deepseekAgent,
    },
    () => {},
    false
  );
  console.log("Complete", result);
};

if (process.argv[1] === __filename) {
  main();
}
